{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SalaheddineAD/vision-transformer/blob/main/notebook/ViT_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDMEQya6Gitc",
        "outputId": "2073374e-edca-4be3-ebd6-bec3e766f1c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m112.6/115.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill\n",
            "Successfully installed dill-0.3.7\n"
          ]
        }
      ],
      "source": [
        "pip install dill"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install vit_keras"
      ],
      "metadata": {
        "id": "oY0hlPXOypUv",
        "outputId": "3a1faa71-d75b-4827-c1bf-0f8c7a7e7f62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vit_keras\n",
            "  Downloading vit_keras-0.1.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from vit_keras) (1.11.2)\n",
            "Collecting validators (from vit_keras)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->vit_keras) (1.23.5)\n",
            "Installing collected packages: validators, vit_keras\n",
            "Successfully installed validators-0.22.0 vit_keras-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTO1lYk1Gitm",
        "outputId": "3f8e70e4-2c83-4687-b55c-4d1ab6ffc85a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/612.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/612.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m604.2/612.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.21.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Qz7SxxMqGitn",
        "outputId": "ff4572a6-d91f-4a33-891a-b269fee80757",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "\n",
        "from vit_keras import vit, utils\n",
        "\n",
        "import time\n",
        "import logging\n",
        "import json\n",
        "import os\n",
        "import dill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERtFUHCAGitr"
      },
      "source": [
        "### Enable tensorflow on gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB3iMNLqGitu",
        "outputId": "258332f3-8e45-4bd1-e788-671a5c489329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 21 22:14:45 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBpicbR0Gitv",
        "outputId": "f376326a-9915-4657-9e0e-ccd108d3de6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: gpu_enabled: command not found\n"
          ]
        }
      ],
      "source": [
        "!gpu_enabled = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob3YtveoGitx",
        "outputId": "d6523ec1-c694-4a5b-ed4d-24350cba3ad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "print(tf.__version__)\n",
        "# ! pip install tensorflow==2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WlIc5GKGity",
        "outputId": "6ddb74e1-9376-4e95-b85f-8b65876d7993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check the number of available GPUs (optional)\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "# Set the GPU as the default device\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "\n",
        "# Now, TensorFlow will use the GPU for all operations by default\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0V1H__L8Git0"
      },
      "outputs": [],
      "source": [
        "def dump_json(data, json_file_path):\n",
        "    with open(json_file_path, 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "def load_json(json_file_path):\n",
        "    with open(json_file_path, 'r') as json_file:\n",
        "        loaded_data = json.load(json_file)\n",
        "    return loaded_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LpsWdb-GGit1"
      },
      "outputs": [],
      "source": [
        "def save_model(model, file_path):\n",
        "    os.makedirs(file_path, exist_ok=True)\n",
        "    model.save(file_path)\n",
        "\n",
        "\n",
        "def load_model(file_path):\n",
        "    loaded_model = tf.keras.models.load_model(file_path)\n",
        "    return loaded_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PpXjKKLLGit2"
      },
      "outputs": [],
      "source": [
        "def get_model_performance_metrics(model, images, labels):\n",
        "    # Evaluating the model\n",
        "    loss, accuracy = model.evaluate(images, labels)\n",
        "\n",
        "    # Getting Precision, Recall, and F1 Score\n",
        "    y_pred = model.predict(images)\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    precision, recall, f1_score, _ = precision_recall_fscore_support(labels, y_pred_labels, average='micro')\n",
        "\n",
        "    performance = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1_score\n",
        "    }\n",
        "    return performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iaRweEIXGit3"
      },
      "outputs": [],
      "source": [
        "def save_model_logs(history,history_path):\n",
        "    # saving logs\n",
        "    logging.basicConfig(filename= history_path, level=logging.INFO)\n",
        "\n",
        "    # Log training history\n",
        "    for epoch, (loss, val_loss) in enumerate(zip(history.history['loss'], history.history['val_loss'])):\n",
        "        logging.info(f\"Epoch {epoch + 1}, Loss: {loss}, Val Loss {val_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IEJfyA2vGit4"
      },
      "outputs": [],
      "source": [
        "def plot_log_function(history):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "r4eQlg6TGit5"
      },
      "outputs": [],
      "source": [
        "def random_transform(image):\n",
        "    choice = random.randint(0, 5)\n",
        "\n",
        "    rows, cols, _ = image.shape\n",
        "\n",
        "    if choice == 0: # Translation\n",
        "        tx, ty = random.randint(-20, 20), random.randint(-20, 20)\n",
        "        M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
        "        return cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "    elif choice == 1: # Rotation\n",
        "        angle = random.randint(-30, 30)\n",
        "        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
        "        return cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "    elif choice == 2: # Scaling\n",
        "        scale_factor = random.uniform(0.8, 1.2)\n",
        "        new_rows, new_cols = int(rows * scale_factor), int(cols * scale_factor)\n",
        "        return cv2.resize(image, (new_cols, new_rows))\n",
        "\n",
        "    elif choice == 3: # Skewing\n",
        "        pts1 = np.float32([[5,5],[20,5],[5,20]])\n",
        "        pt1 = 5+10*np.random.uniform()-10/2\n",
        "        pt2 = 20+10*np.random.uniform()-10/2\n",
        "        pts2 = np.float32([[pt1,5],[pt2,pt1],[5,pt2]])\n",
        "        M = cv2.getAffineTransform(pts1,pts2)\n",
        "        return cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "    elif choice == 4: # Perspective distortion\n",
        "        pts1 = np.float32([[5,5],[20,5],[5,20],[20,20]])\n",
        "        pts2 = np.float32([[0,0],[20,5],[5,20],[20,20]])\n",
        "        M = cv2.getPerspectiveTransform(pts1,pts2)\n",
        "        return cv2.warpPerspective(image, M, (cols, rows))\n",
        "\n",
        "    else: # Pincushion distortion\n",
        "        distortion = np.float32([1, 1, 0, 0])\n",
        "        camera_matrix = np.eye(3)\n",
        "        return cv2.undistort(image, camera_matrix, distortion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gAZLIzJRGit7"
      },
      "outputs": [],
      "source": [
        "def get_transformed_test_images(test_images):\n",
        "    transformed_test_images = []\n",
        "    for img in test_images:\n",
        "        transformed_img = random_transform(img)\n",
        "        transformed_test_images.append(transformed_img)\n",
        "\n",
        "    # resizing transformed_test_images into (32, 32)\n",
        "    new_shape = (32, 32)\n",
        "    transformed_test_images = np.array([cv2.resize(img, new_shape).reshape(32, 32, 1) for img in transformed_test_images])\n",
        "\n",
        "    # Checking for shape consistency\n",
        "\n",
        "    good_shape = test_images[0].shape\n",
        "    for i, img in enumerate(transformed_test_images):\n",
        "        if img.shape != good_shape:\n",
        "            print(f\"Inconsistent shape at index {i}: expected {good_shape}, but got {img.shape}\")\n",
        "    return transformed_test_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KizrZqGGit8"
      },
      "source": [
        "# 1 mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KgtBjt-RGit9",
        "outputId": "508b6885-045d-45ed-9c04-5af1db962413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Shuffle the training data and labels\n",
        "shuffle_index_train = np.random.permutation(len(train_images))\n",
        "train_images = train_images[shuffle_index_train]\n",
        "train_labels = train_labels[shuffle_index_train]\n",
        "\n",
        "# Shuffle the testing data and labels\n",
        "shuffle_index_test = np.random.permutation(len(test_images))\n",
        "test_images = test_images[shuffle_index_test]\n",
        "test_labels = test_labels[shuffle_index_test]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ayt-GU0rsdSh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gLyffGqOGit-"
      },
      "outputs": [],
      "source": [
        "# Preprocess images\n",
        "new_shape = (32, 32)\n",
        "train_images = np.array([cv2.resize(img, new_shape) for img in train_images])\n",
        "test_images = np.array([cv2.resize(img, new_shape) for img in test_images])\n",
        "\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "train_images = train_images[..., tf.newaxis].astype(\"float32\")\n",
        "test_images = test_images[..., tf.newaxis].astype(\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2EKFGVTGiuB",
        "outputId": "af15b325-fc41-4ceb-c2de-73635b06c538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images size:  (54000, 32, 32, 1)  and val_images size:  (6000, 32, 32, 1)\n",
            "train_labels size:  (54000,)  and val_labels size:  (6000,)\n"
          ]
        }
      ],
      "source": [
        "# creating validation images val_images\n",
        "val_size = int(len(train_labels)*0.10)\n",
        "\n",
        "train_images , val_images= train_images[val_size:], train_images[:val_size]\n",
        "print(\"train_images size: \", train_images.shape, \" and val_images size: \", val_images.shape)\n",
        "\n",
        "train_labels , val_labels= train_labels[val_size:], train_labels[:val_size]\n",
        "print(\"train_labels size: \", train_labels.shape, \" and val_labels size: \", val_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJFxwUorGiuC"
      },
      "source": [
        "## 1-1 Vision Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "j-UH-BkQGiuD"
      },
      "outputs": [],
      "source": [
        "# Build the ViT model\n",
        "\n",
        "def create_vit_model(input_shape = (*new_shape, 1),  patch_size = 4, num_heads = 12, projection_dim = 32, num_transformer_layers = 12, mlp_head_units = [64, 32]):\n",
        "\n",
        "    num_patches = (new_shape[0] // patch_size) * (new_shape[1] // patch_size)\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(3, (3, 3), padding=\"same\")(inputs)  # Convert to 3 channels\n",
        "    x = tf.keras.layers.Rescaling(1.0 / 255)(x)  # Rescale\n",
        "    x = tf.keras.layers.Conv2D(32, (patch_size, patch_size), strides=patch_size)(x)\n",
        "    x = tf.keras.layers.Reshape((num_patches, 32))(x)\n",
        "\n",
        "    for _ in range(num_transformer_layers):\n",
        "        x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        attention_output = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        x2 = tf.keras.layers.Add()([attention_output, x])\n",
        "        x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = tf.keras.layers.Conv1D(64, 2, padding=\"same\", activation=\"relu\")(x3)\n",
        "        x3 = tf.keras.layers.Dropout(0.1)(x3)\n",
        "        x3 = tf.keras.layers.Conv1D(32, 2, padding=\"same\")(x3)\n",
        "        x = tf.keras.layers.Add()([x3, x2])\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    for dim in mlp_head_units:\n",
        "        x = tf.keras.layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = tf.keras.layers.Dropout(0.1)(x)\n",
        "    outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from vit_keras import vit\n",
        "def build_vit_model(input_shape, num_classes=3):\n",
        "\n",
        "  input_layer = Input(input_shape)\n",
        "  replicated_channels = Concatenate(axis=-1)([input_layer] * 3)\n",
        "\n",
        "  vit_model = vit.vit_b32(\n",
        "      image_size=input_shape[0],\n",
        "      activation='softmax',\n",
        "      pretrained=True,\n",
        "      include_top=True,\n",
        "      pretrained_top=False,\n",
        "      classes=num_classes)(replicated_channels)\n",
        "\n",
        "  return Model(inputs=input_layer, outputs=vit_model)"
      ],
      "metadata": {
        "id": "VvKldWcByBtw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vS-9t3jJGiuF",
        "outputId": "2de96dbb-9670-4128-d676-142d03780d48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-B_32_imagenet21k+imagenet2012.npz\n",
            "353253686/353253686 [==============================] - 7s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/vit_keras/utils.py:81: UserWarning: Resizing position embeddings from 12, 12 to 1, 1\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# model = create_vit_model(input_shape = (*new_shape, 1),  patch_size = 4, num_heads = 2, projection_dim = 32, num_transformer_layers = 32, mlp_head_units = [64, 32])\n",
        "model = build_vit_model((32,32,1), num_classes = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HZ5uD8dVGiuG"
      },
      "outputs": [],
      "source": [
        "hyperparameters={\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 10,\n",
        "    \"optimizer\":\"adam\",\n",
        "    'early_stopping_patience':10,\n",
        "    \"learning_rate\":0.001,\n",
        "    \"weight_decay\" : 0.0001\n",
        "}\n",
        "\n",
        "def train_individual_model(model, train_images, train_labels, val_data, batch_size=hyperparameters['batch_size'], epochs=hyperparameters['epochs'], patience =hyperparameters['early_stopping_patience'], learning_rate= hyperparameters[\"learning_rate\"], weight_decay = hyperparameters[\"weight_decay\"] ):\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "    model.compile(optimizer=optimizer,\n",
        "\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "\n",
        "                  metrics=['accuracy'])\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience= patience, verbose=1, restore_best_weights=True)\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(train_images,train_labels, validation_data=val_data, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
        "    end_time = time.time()\n",
        "    print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    # Using history to print training metrics\n",
        "    print(\"\\nTraining Metrics:\")\n",
        "    print(f\"Loss: {history.history['loss'][-1]}\")\n",
        "    print(f\"Accuracy: {history.history['accuracy'][-1]}\")\n",
        "\n",
        "    # Using history to print validation metrics\n",
        "    print(\"\\nValidation Metrics:\")\n",
        "    print(f\"Loss: {history.history['val_loss'][-1]}\")\n",
        "    print(f\"Accuracy: {history.history['val_accuracy'][-1]}\")\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history= train_individual_model(model, train_images,train_labels, val_data = (val_images, val_labels), batch_size=hyperparameters['batch_size'], epochs=hyperparameters['epochs'], patience =hyperparameters['early_stopping_patience'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhUU6HmoM6O6",
        "outputId": "468d79bc-ed91-44f0-e3a6-3f70db4a9a64"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "211/211 [==============================] - 47s 146ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0769 - val_accuracy: 0.9847\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 28s 134ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0770 - val_accuracy: 0.9823\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 29s 136ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0927 - val_accuracy: 0.9782\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 29s 136ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0698 - val_accuracy: 0.9840\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 29s 138ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0626 - val_accuracy: 0.9853\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 29s 138ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.0620 - val_accuracy: 0.9860\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.0687 - val_accuracy: 0.9840\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0734 - val_accuracy: 0.9837\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 30s 140ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.0753 - val_accuracy: 0.9827\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 30s 140ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.0702 - val_accuracy: 0.9848\n",
            "Training time: 308.96 seconds\n",
            "\n",
            "Training Metrics:\n",
            "Loss: 0.010192756541073322\n",
            "Accuracy: 0.9966296553611755\n",
            "\n",
            "Validation Metrics:\n",
            "Loss: 0.07019025832414627\n",
            "Accuracy: 0.9848333597183228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_guB22SEXMK8",
        "outputId": "e536e663-9438-4dce-adf9-101cff86dad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "99wgN40YGiuJ"
      },
      "outputs": [],
      "source": [
        "#saving model\n",
        "path = os.path.join(\"/content/drive/My Drive/ML_research/experiments/\",'vit_32_fine_tuned_mnist', 'model')\n",
        "save_model(model, path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.exists(os.path.join(\"/content/drive/My Drive/ML_research/experiments/\",'vit_32_fine_tuned_mnist', 'model'))"
      ],
      "metadata": {
        "id": "Ukb4fPP0ahKC",
        "outputId": "5b63e5cd-8b64-4127-a07c-f61c38462e66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the performance on taining_data\n",
        "plot_log_function(history)"
      ],
      "metadata": {
        "id": "dmviIkcq87FG",
        "outputId": "dc2c5696-7a4e-4e06-f364-c21ff16ed3f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "opFeAG7QGiuK"
      },
      "outputs": [],
      "source": [
        "history_path = os.path.join(\"/content/drive/My Drive/ML_research/experiments/vit_32_fine_tuned_mnist\", 'history.log')\n",
        "save_model_logs(history,history_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fcow7MVOGiuL"
      },
      "outputs": [],
      "source": [
        "path = os.path.join(\"/content/drive/My Drive/ML_research/experiments/\",'vit_32_fine_tuned_mnist', 'model')\n",
        "\n",
        "model2 = load_model(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "X1TvBzL3GiuM",
        "outputId": "d01fbd74-0aaa-4aae-95e7-3c7839374c67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': 'ViT-32 pretrained', 'hyperparameters': {'batch_size': 256, 'epochs': 10, 'optimizer': 'adam', 'early_stopping_patience': 10, 'learning_rate': 0.001, 'weight_decay': 0.0001}, 'model_architecture': {'class_name': 'Functional', 'config': {'name': 'model', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_input_shape': [None, 32, 32, 1], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_1'}, 'registered_name': None, 'name': 'input_1', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Concatenate', 'config': {'name': 'concatenate', 'trainable': True, 'dtype': 'float32', 'axis': -1}, 'registered_name': None, 'build_config': {'input_shape': [[None, 32, 32, 1], [None, 32, 32, 1], [None, 32, 32, 1]]}, 'name': 'concatenate', 'inbound_nodes': [[['input_1', 0, 0, {}], ['input_1', 0, 0, {}], ['input_1', 0, 0, {}]]]}, {'module': 'keras.src.engine.functional', 'class_name': 'Functional', 'config': {'name': 'vit-b32', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_input_shape': [None, 32, 32, 3], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_2'}, 'registered_name': None, 'name': 'input_2', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'embedding', 'trainable': True, 'dtype': 'float32', 'filters': 768, 'kernel_size': [32, 32], 'strides': [32, 32], 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 32, 32, 3]}, 'name': 'embedding', 'inbound_nodes': [[['input_2', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Reshape', 'config': {'name': 'reshape', 'trainable': True, 'dtype': 'float32', 'target_shape': [1, 768]}, 'registered_name': None, 'build_config': {'input_shape': [None, 1, 1, 768]}, 'name': 'reshape', 'inbound_nodes': [[['embedding', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'ClassToken', 'config': {'name': 'class_token', 'trainable': True, 'dtype': 'float32'}, 'registered_name': 'Custom>ClassToken', 'build_config': {'input_shape': [None, 1, 768]}, 'name': 'class_token', 'inbound_nodes': [[['reshape', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'AddPositionEmbs', 'config': {'name': 'Transformer/posembed_input', 'trainable': True, 'dtype': 'float32'}, 'registered_name': 'Custom>AddPositionEmbs', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/posembed_input', 'inbound_nodes': [[['class_token', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'TransformerBlock', 'config': {'name': 'Transformer/encoderblock_0', 'trainable': True, 'dtype': 'float32', 'num_heads': 12, 'mlp_dim': 3072, 'dropout': 0.1}, 'registered_name': 'Custom>TransformerBlock', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoderblock_0', 'inbound_nodes': [[['Transformer/posembed_input', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'TransformerBlock', 'config': {'name': 'Transformer/encoderblock_1', 'trainable': True, 'dtype': 'float32', 'num_heads': 12, 'mlp_dim': 3072, 'dropout': 0.1}, 'registered_name': 'Custom>TransformerBlock', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoderblock_1', 'inbound_nodes': [[['Transformer/encoderblock_0', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'TransformerBlock', 'config': {'name': 'Transformer/encoderblock_2', 'trainable': True, 'dtype': 'float32', 'num_heads': 12, 'mlp_dim': 3072, 'dropout': 0.1}, 'registered_name': 'Custom>TransformerBlock', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoderblock_2', 'inbound_nodes': [[['Transformer/encoderblock_1', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'TransformerBlock', 'config': {'name': 'Transformer/encoderblock_3', 'trainable': True, 'dtype': 'float32', 'num_heads': 12, 'mlp_dim': 3072, 'dropout': 0.1}, 'registered_name': 'Custom>TransformerBlock', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoderblock_3', 'inbound_nodes': [[['Transformer/encoderblock_2', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'TransformerBlock', 'config': {'name': 'Transformer/encoderblock_4', 'trainable': True, 'dtype': 'float32', 'num_heads': 12, 'mlp_dim': 3072, 'dropout': 0.1}, 'registered_name': 'Custom>TransformerBlock', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoderblock_4', 'inbound_nodes': [[['Transformer/encoderblock_3', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'TransformerBlock', 'config': {'name': 'Transformer/encoderblock_5', 'trainable': True, 'dtype': 'float32', 'num_heads': 12, 'mlp_dim': 3072, 'dropout': 0.1}, 'registered_name': 'Custom>TransformerBlock', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoderblock_5', 'inbound_nodes': [[['Transformer/encoderblock_4', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'TransformerBlock', 'config': {'name': 'Transformer/encoderblock_6', 'trainable': True, 'dtype': 'float32', 'num_heads': 12, 'mlp_dim': 3072, 'dropout': 0.1}, 'registered_name': 'Custom>TransformerBlock', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoderblock_6', 'inbound_nodes': [[['Transformer/encoderblock_5', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'TransformerBlock', 'config': {'name': 'Transformer/encoderblock_7', 'trainable': True, 'dtype': 'float32', 'num_heads': 12, 'mlp_dim': 3072, 'dropout': 0.1}, 'registered_name': 'Custom>TransformerBlock', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoderblock_7', 'inbound_nodes': [[['Transformer/encoderblock_6', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'TransformerBlock', 'config': {'name': 'Transformer/encoderblock_8', 'trainable': True, 'dtype': 'float32', 'num_heads': 12, 'mlp_dim': 3072, 'dropout': 0.1}, 'registered_name': 'Custom>TransformerBlock', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoderblock_8', 'inbound_nodes': [[['Transformer/encoderblock_7', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'TransformerBlock', 'config': {'name': 'Transformer/encoderblock_9', 'trainable': True, 'dtype': 'float32', 'num_heads': 12, 'mlp_dim': 3072, 'dropout': 0.1}, 'registered_name': 'Custom>TransformerBlock', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoderblock_9', 'inbound_nodes': [[['Transformer/encoderblock_8', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'TransformerBlock', 'config': {'name': 'Transformer/encoderblock_10', 'trainable': True, 'dtype': 'float32', 'num_heads': 12, 'mlp_dim': 3072, 'dropout': 0.1}, 'registered_name': 'Custom>TransformerBlock', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoderblock_10', 'inbound_nodes': [[['Transformer/encoderblock_9', 0, 0, {}]]]}, {'module': 'vit_keras.layers', 'class_name': 'TransformerBlock', 'config': {'name': 'Transformer/encoderblock_11', 'trainable': True, 'dtype': 'float32', 'num_heads': 12, 'mlp_dim': 3072, 'dropout': 0.1}, 'registered_name': 'Custom>TransformerBlock', 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoderblock_11', 'inbound_nodes': [[['Transformer/encoderblock_10', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'LayerNormalization', 'config': {'name': 'Transformer/encoder_norm', 'trainable': True, 'dtype': 'float32', 'axis': [2], 'epsilon': 1e-06, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'Transformer/encoder_norm', 'inbound_nodes': [[['Transformer/encoderblock_11', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Lambda', 'config': {'name': 'ExtractToken', 'trainable': True, 'dtype': 'float32', 'function': ['4wEAAAAAAAAAAAAAAAEAAAADAAAAUwAAAHMQAAAAfABkAGQAhQJkAWYCGQBTACkCTukAAAAAqQCp\\nAdoBdnICAAAAcgIAAAD6OC91c3IvbG9jYWwvbGliL3B5dGhvbjMuMTAvZGlzdC1wYWNrYWdlcy92\\naXRfa2VyYXMvdml0LnB52gg8bGFtYmRhPnoAAABzAgAAABAA\\n', None, None], 'function_type': 'lambda', 'module': 'vit_keras.vit', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}, 'registered_name': None, 'build_config': {'input_shape': [None, 2, 768]}, 'name': 'ExtractToken', 'inbound_nodes': [[['Transformer/encoder_norm', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'head', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 768]}, 'name': 'head', 'inbound_nodes': [[['ExtractToken', 0, 0, {}]]]}], 'input_layers': [['input_2', 0, 0]], 'output_layers': [['head', 0, 0]]}, 'registered_name': 'Functional', 'build_config': {'input_shape': [None, 32, 32, 3]}, 'name': 'vit-b32', 'inbound_nodes': [[['concatenate', 0, 0, {}]]]}], 'input_layers': [['input_1', 0, 0]], 'output_layers': [['vit-b32', 1, 0]]}, 'keras_version': '2.13.1', 'backend': 'tensorflow'}}\n"
          ]
        }
      ],
      "source": [
        "# saving model architecture and hypermarameters\n",
        "model_info = {\n",
        "    \"model_name\": \"ViT-32 pretrained\"\n",
        "}\n",
        "model_info[\"hyperparameters\"] = hyperparameters\n",
        "model_info[\"model_architecture\"] = model.to_json()\n",
        "model_info[\"model_architecture\"]  = json.loads(model_info[\"model_architecture\"] )\n",
        "\n",
        "path = os.path.join(\"/content/drive/My Drive/ML_research/experiments/\",'vit_32_fine_tuned_mnist', 'model_architecture.json')\n",
        "dump_json(model_info, path )\n",
        "print(model_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_json(os.path.join(\"/content/drive/My Drive/ML_research/experiments/\",'vit_32_fine_tuned_mnist', 'model_architecture.json'))\n"
      ],
      "metadata": {
        "id": "17QbTBFicsXl",
        "outputId": "760285ac-5969-4c0e-ac14-58f59cb313ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'ViT-32 pretrained',\n",
              " 'hyperparameters': {'batch_size': 256,\n",
              "  'epochs': 10,\n",
              "  'optimizer': 'adam',\n",
              "  'early_stopping_patience': 10,\n",
              "  'learning_rate': 0.001,\n",
              "  'weight_decay': 0.0001},\n",
              " 'model_architecture': {'class_name': 'Functional',\n",
              "  'config': {'name': 'model',\n",
              "   'trainable': True,\n",
              "   'layers': [{'module': 'keras.layers',\n",
              "     'class_name': 'InputLayer',\n",
              "     'config': {'batch_input_shape': [None, 32, 32, 1],\n",
              "      'dtype': 'float32',\n",
              "      'sparse': False,\n",
              "      'ragged': False,\n",
              "      'name': 'input_1'},\n",
              "     'registered_name': None,\n",
              "     'name': 'input_1',\n",
              "     'inbound_nodes': []},\n",
              "    {'module': 'keras.layers',\n",
              "     'class_name': 'Concatenate',\n",
              "     'config': {'name': 'concatenate',\n",
              "      'trainable': True,\n",
              "      'dtype': 'float32',\n",
              "      'axis': -1},\n",
              "     'registered_name': None,\n",
              "     'build_config': {'input_shape': [[None, 32, 32, 1],\n",
              "       [None, 32, 32, 1],\n",
              "       [None, 32, 32, 1]]},\n",
              "     'name': 'concatenate',\n",
              "     'inbound_nodes': [[['input_1', 0, 0, {}],\n",
              "       ['input_1', 0, 0, {}],\n",
              "       ['input_1', 0, 0, {}]]]},\n",
              "    {'module': 'keras.src.engine.functional',\n",
              "     'class_name': 'Functional',\n",
              "     'config': {'name': 'vit-b32',\n",
              "      'trainable': True,\n",
              "      'layers': [{'module': 'keras.layers',\n",
              "        'class_name': 'InputLayer',\n",
              "        'config': {'batch_input_shape': [None, 32, 32, 3],\n",
              "         'dtype': 'float32',\n",
              "         'sparse': False,\n",
              "         'ragged': False,\n",
              "         'name': 'input_2'},\n",
              "        'registered_name': None,\n",
              "        'name': 'input_2',\n",
              "        'inbound_nodes': []},\n",
              "       {'module': 'keras.layers',\n",
              "        'class_name': 'Conv2D',\n",
              "        'config': {'name': 'embedding',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'filters': 768,\n",
              "         'kernel_size': [32, 32],\n",
              "         'strides': [32, 32],\n",
              "         'padding': 'valid',\n",
              "         'data_format': 'channels_last',\n",
              "         'dilation_rate': [1, 1],\n",
              "         'groups': 1,\n",
              "         'activation': 'linear',\n",
              "         'use_bias': True,\n",
              "         'kernel_initializer': {'module': 'keras.initializers',\n",
              "          'class_name': 'GlorotUniform',\n",
              "          'config': {'seed': None},\n",
              "          'registered_name': None},\n",
              "         'bias_initializer': {'module': 'keras.initializers',\n",
              "          'class_name': 'Zeros',\n",
              "          'config': {},\n",
              "          'registered_name': None},\n",
              "         'kernel_regularizer': None,\n",
              "         'bias_regularizer': None,\n",
              "         'activity_regularizer': None,\n",
              "         'kernel_constraint': None,\n",
              "         'bias_constraint': None},\n",
              "        'registered_name': None,\n",
              "        'build_config': {'input_shape': [None, 32, 32, 3]},\n",
              "        'name': 'embedding',\n",
              "        'inbound_nodes': [[['input_2', 0, 0, {}]]]},\n",
              "       {'module': 'keras.layers',\n",
              "        'class_name': 'Reshape',\n",
              "        'config': {'name': 'reshape',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'target_shape': [1, 768]},\n",
              "        'registered_name': None,\n",
              "        'build_config': {'input_shape': [None, 1, 1, 768]},\n",
              "        'name': 'reshape',\n",
              "        'inbound_nodes': [[['embedding', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'ClassToken',\n",
              "        'config': {'name': 'class_token',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32'},\n",
              "        'registered_name': 'Custom>ClassToken',\n",
              "        'build_config': {'input_shape': [None, 1, 768]},\n",
              "        'name': 'class_token',\n",
              "        'inbound_nodes': [[['reshape', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'AddPositionEmbs',\n",
              "        'config': {'name': 'Transformer/posembed_input',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32'},\n",
              "        'registered_name': 'Custom>AddPositionEmbs',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/posembed_input',\n",
              "        'inbound_nodes': [[['class_token', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'TransformerBlock',\n",
              "        'config': {'name': 'Transformer/encoderblock_0',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'num_heads': 12,\n",
              "         'mlp_dim': 3072,\n",
              "         'dropout': 0.1},\n",
              "        'registered_name': 'Custom>TransformerBlock',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoderblock_0',\n",
              "        'inbound_nodes': [[['Transformer/posembed_input', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'TransformerBlock',\n",
              "        'config': {'name': 'Transformer/encoderblock_1',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'num_heads': 12,\n",
              "         'mlp_dim': 3072,\n",
              "         'dropout': 0.1},\n",
              "        'registered_name': 'Custom>TransformerBlock',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoderblock_1',\n",
              "        'inbound_nodes': [[['Transformer/encoderblock_0', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'TransformerBlock',\n",
              "        'config': {'name': 'Transformer/encoderblock_2',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'num_heads': 12,\n",
              "         'mlp_dim': 3072,\n",
              "         'dropout': 0.1},\n",
              "        'registered_name': 'Custom>TransformerBlock',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoderblock_2',\n",
              "        'inbound_nodes': [[['Transformer/encoderblock_1', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'TransformerBlock',\n",
              "        'config': {'name': 'Transformer/encoderblock_3',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'num_heads': 12,\n",
              "         'mlp_dim': 3072,\n",
              "         'dropout': 0.1},\n",
              "        'registered_name': 'Custom>TransformerBlock',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoderblock_3',\n",
              "        'inbound_nodes': [[['Transformer/encoderblock_2', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'TransformerBlock',\n",
              "        'config': {'name': 'Transformer/encoderblock_4',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'num_heads': 12,\n",
              "         'mlp_dim': 3072,\n",
              "         'dropout': 0.1},\n",
              "        'registered_name': 'Custom>TransformerBlock',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoderblock_4',\n",
              "        'inbound_nodes': [[['Transformer/encoderblock_3', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'TransformerBlock',\n",
              "        'config': {'name': 'Transformer/encoderblock_5',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'num_heads': 12,\n",
              "         'mlp_dim': 3072,\n",
              "         'dropout': 0.1},\n",
              "        'registered_name': 'Custom>TransformerBlock',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoderblock_5',\n",
              "        'inbound_nodes': [[['Transformer/encoderblock_4', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'TransformerBlock',\n",
              "        'config': {'name': 'Transformer/encoderblock_6',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'num_heads': 12,\n",
              "         'mlp_dim': 3072,\n",
              "         'dropout': 0.1},\n",
              "        'registered_name': 'Custom>TransformerBlock',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoderblock_6',\n",
              "        'inbound_nodes': [[['Transformer/encoderblock_5', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'TransformerBlock',\n",
              "        'config': {'name': 'Transformer/encoderblock_7',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'num_heads': 12,\n",
              "         'mlp_dim': 3072,\n",
              "         'dropout': 0.1},\n",
              "        'registered_name': 'Custom>TransformerBlock',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoderblock_7',\n",
              "        'inbound_nodes': [[['Transformer/encoderblock_6', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'TransformerBlock',\n",
              "        'config': {'name': 'Transformer/encoderblock_8',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'num_heads': 12,\n",
              "         'mlp_dim': 3072,\n",
              "         'dropout': 0.1},\n",
              "        'registered_name': 'Custom>TransformerBlock',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoderblock_8',\n",
              "        'inbound_nodes': [[['Transformer/encoderblock_7', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'TransformerBlock',\n",
              "        'config': {'name': 'Transformer/encoderblock_9',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'num_heads': 12,\n",
              "         'mlp_dim': 3072,\n",
              "         'dropout': 0.1},\n",
              "        'registered_name': 'Custom>TransformerBlock',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoderblock_9',\n",
              "        'inbound_nodes': [[['Transformer/encoderblock_8', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'TransformerBlock',\n",
              "        'config': {'name': 'Transformer/encoderblock_10',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'num_heads': 12,\n",
              "         'mlp_dim': 3072,\n",
              "         'dropout': 0.1},\n",
              "        'registered_name': 'Custom>TransformerBlock',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoderblock_10',\n",
              "        'inbound_nodes': [[['Transformer/encoderblock_9', 0, 0, {}]]]},\n",
              "       {'module': 'vit_keras.layers',\n",
              "        'class_name': 'TransformerBlock',\n",
              "        'config': {'name': 'Transformer/encoderblock_11',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'num_heads': 12,\n",
              "         'mlp_dim': 3072,\n",
              "         'dropout': 0.1},\n",
              "        'registered_name': 'Custom>TransformerBlock',\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoderblock_11',\n",
              "        'inbound_nodes': [[['Transformer/encoderblock_10', 0, 0, {}]]]},\n",
              "       {'module': 'keras.layers',\n",
              "        'class_name': 'LayerNormalization',\n",
              "        'config': {'name': 'Transformer/encoder_norm',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'axis': [2],\n",
              "         'epsilon': 1e-06,\n",
              "         'center': True,\n",
              "         'scale': True,\n",
              "         'beta_initializer': {'module': 'keras.initializers',\n",
              "          'class_name': 'Zeros',\n",
              "          'config': {},\n",
              "          'registered_name': None},\n",
              "         'gamma_initializer': {'module': 'keras.initializers',\n",
              "          'class_name': 'Ones',\n",
              "          'config': {},\n",
              "          'registered_name': None},\n",
              "         'beta_regularizer': None,\n",
              "         'gamma_regularizer': None,\n",
              "         'beta_constraint': None,\n",
              "         'gamma_constraint': None},\n",
              "        'registered_name': None,\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'Transformer/encoder_norm',\n",
              "        'inbound_nodes': [[['Transformer/encoderblock_11', 0, 0, {}]]]},\n",
              "       {'module': 'keras.layers',\n",
              "        'class_name': 'Lambda',\n",
              "        'config': {'name': 'ExtractToken',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'function': ['4wEAAAAAAAAAAAAAAAEAAAADAAAAUwAAAHMQAAAAfABkAGQAhQJkAWYCGQBTACkCTukAAAAAqQCp\\nAdoBdnICAAAAcgIAAAD6OC91c3IvbG9jYWwvbGliL3B5dGhvbjMuMTAvZGlzdC1wYWNrYWdlcy92\\naXRfa2VyYXMvdml0LnB52gg8bGFtYmRhPnoAAABzAgAAABAA\\n',\n",
              "          None,\n",
              "          None],\n",
              "         'function_type': 'lambda',\n",
              "         'module': 'vit_keras.vit',\n",
              "         'output_shape': None,\n",
              "         'output_shape_type': 'raw',\n",
              "         'output_shape_module': None,\n",
              "         'arguments': {}},\n",
              "        'registered_name': None,\n",
              "        'build_config': {'input_shape': [None, 2, 768]},\n",
              "        'name': 'ExtractToken',\n",
              "        'inbound_nodes': [[['Transformer/encoder_norm', 0, 0, {}]]]},\n",
              "       {'module': 'keras.layers',\n",
              "        'class_name': 'Dense',\n",
              "        'config': {'name': 'head',\n",
              "         'trainable': True,\n",
              "         'dtype': 'float32',\n",
              "         'units': 10,\n",
              "         'activation': 'softmax',\n",
              "         'use_bias': True,\n",
              "         'kernel_initializer': {'module': 'keras.initializers',\n",
              "          'class_name': 'GlorotUniform',\n",
              "          'config': {'seed': None},\n",
              "          'registered_name': None},\n",
              "         'bias_initializer': {'module': 'keras.initializers',\n",
              "          'class_name': 'Zeros',\n",
              "          'config': {},\n",
              "          'registered_name': None},\n",
              "         'kernel_regularizer': None,\n",
              "         'bias_regularizer': None,\n",
              "         'activity_regularizer': None,\n",
              "         'kernel_constraint': None,\n",
              "         'bias_constraint': None},\n",
              "        'registered_name': None,\n",
              "        'build_config': {'input_shape': [None, 768]},\n",
              "        'name': 'head',\n",
              "        'inbound_nodes': [[['ExtractToken', 0, 0, {}]]]}],\n",
              "      'input_layers': [['input_2', 0, 0]],\n",
              "      'output_layers': [['head', 0, 0]]},\n",
              "     'registered_name': 'Functional',\n",
              "     'build_config': {'input_shape': [None, 32, 32, 3]},\n",
              "     'name': 'vit-b32',\n",
              "     'inbound_nodes': [[['concatenate', 0, 0, {}]]]}],\n",
              "   'input_layers': [['input_1', 0, 0]],\n",
              "   'output_layers': [['vit-b32', 1, 0]]},\n",
              "  'keras_version': '2.13.1',\n",
              "  'backend': 'tensorflow'}}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uYkHMtFXGiuN"
      },
      "outputs": [],
      "source": [
        "transformed_test_images= get_transformed_test_images(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "cXuvne_5GiuO",
        "outputId": "551424a9-f348-4e5c-ea10-c6d6a07e727d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': 'ViT-32 pretrained', 'train_images_performance_metrics': {'accuracy': 0.9985555410385132, 'precision': 0.9985555555555555, 'recall': 0.9985555555555555, 'f1_score': 0.9985555555555555}, 'validation_images_performance_metrics': {'accuracy': 0.9848333597183228, 'precision': 0.9848333333333333, 'recall': 0.9848333333333333, 'f1_score': 0.9848333333333333}, 'test_images_performance_metrics': {'accuracy': 0.9851999878883362, 'precision': 0.9852, 'recall': 0.9852, 'f1_score': 0.9852}, 'transformed_test_images_performance_metrics': {'accuracy': 0.605400025844574, 'precision': 0.6054, 'recall': 0.6054, 'f1_score': 0.6054}}\n"
          ]
        }
      ],
      "source": [
        "# #saving model performance metrics\n",
        "# model_performance_metrics = {\n",
        "#     \"model_name\": \"ViT-32 pretrained\"\n",
        "# }\n",
        "# model_performance_metrics[\"train_images_performance_metrics\"] = get_model_performance_metrics(model,train_images, train_labels)\n",
        "# model_performance_metrics[\"validation_images_performance_metrics\"] = get_model_performance_metrics(model,val_images, val_labels)\n",
        "# model_performance_metrics[\"test_images_performance_metrics\"] = get_model_performance_metrics(model, test_images, test_labels)\n",
        "# model_performance_metrics[\"transformed_test_images_performance_metrics\"] = get_model_performance_metrics(model, transformed_test_images, test_labels)\n",
        "\n",
        "performance_path = os.path.join(\"/content/drive/My Drive/ML_research/experiments/\",'vit_32_fine_tuned_mnist', 'model_performance_metrics.json')\n",
        "dump_json(model_performance_metrics, performance_path)\n",
        "print(model_performance_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b1aTZVOgALJ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}