{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SalaheddineAD/vision-transformer/blob/main/notebook/ViT_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDMEQya6Gitc",
        "outputId": "796888de-29fe-468c-e1bc-c197e5bc6297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/115.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill\n",
            "Successfully installed dill-0.3.7\n"
          ]
        }
      ],
      "source": [
        "pip install dill"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install vit_keras"
      ],
      "metadata": {
        "id": "oY0hlPXOypUv",
        "outputId": "c83cd826-ccf7-45da-e6e9-48599150b144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vit_keras\n",
            "  Downloading vit_keras-0.1.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from vit_keras) (1.11.2)\n",
            "Collecting validators (from vit_keras)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->vit_keras) (1.23.5)\n",
            "Installing collected packages: validators, vit_keras\n",
            "Successfully installed validators-0.22.0 vit_keras-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTO1lYk1Gitm",
        "outputId": "f4ebeee0-92f6-4c76-c251-79039b8b1ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/612.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/612.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m450.6/612.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.21.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qz7SxxMqGitn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from vit_keras import vit, utils\n",
        "\n",
        "import time\n",
        "import logging\n",
        "import json\n",
        "import os\n",
        "import dill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERtFUHCAGitr"
      },
      "source": [
        "### Enable tensorflow on gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB3iMNLqGitu",
        "outputId": "cdd7d8b3-2a25-4a32-b76c-c33e3af15d36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 15 21:41:41 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    45W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBpicbR0Gitv",
        "outputId": "f258f41e-f3e4-41ca-b6f5-7ed059cf4ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: gpu_enabled: command not found\n"
          ]
        }
      ],
      "source": [
        "!gpu_enabled = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob3YtveoGitx",
        "outputId": "12f7109f-72c4-490c-f4a4-e662a577fc9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "print(tf.__version__)\n",
        "# ! pip install tensorflow==2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WlIc5GKGity",
        "outputId": "2beb078d-1c99-4301-8750-c006eaa4148f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check the number of available GPUs (optional)\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "# Set the GPU as the default device\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "\n",
        "# Now, TensorFlow will use the GPU for all operations by default\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zGLSo_xafDkk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0V1H__L8Git0"
      },
      "outputs": [],
      "source": [
        "def dump_json(data, json_file_path):\n",
        "    with open(json_file_path, 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "def load_json(json_file_path):\n",
        "    with open(json_file_path, 'r') as json_file:\n",
        "        loaded_data = json.load(json_file)\n",
        "    return loaded_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LpsWdb-GGit1"
      },
      "outputs": [],
      "source": [
        "def save_model(model, file_path):\n",
        "    os.makedirs(file_path, exist_ok=True)\n",
        "    model.save(file_path)\n",
        "\n",
        "\n",
        "def load_model(file_path):\n",
        "    loaded_model = tf.keras.models.load_model(file_path)\n",
        "    return loaded_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PpXjKKLLGit2"
      },
      "outputs": [],
      "source": [
        "def get_model_performance_metrics(model, images, labels):\n",
        "    # Evaluating the model\n",
        "    loss, accuracy = model.evaluate(images, labels)\n",
        "\n",
        "    # Getting Precision, Recall, and F1 Score\n",
        "    y_pred = model.predict(images)\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    precision, recall, f1_score, _ = precision_recall_fscore_support(labels, y_pred_labels, average='macro')\n",
        "    performance = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1_score\n",
        "    }\n",
        "    return performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iaRweEIXGit3"
      },
      "outputs": [],
      "source": [
        "def save_model_logs(history,history_path):\n",
        "    # saving logs\n",
        "    logging.basicConfig(filename= history_path, level=logging.INFO)\n",
        "\n",
        "    # Log training history\n",
        "    for epoch, (loss, val_loss) in enumerate(zip(history.history['loss'], history.history['val_loss'])):\n",
        "        logging.info(f\"Epoch {epoch + 1}, Loss: {loss}, Val Loss {val_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IEJfyA2vGit4"
      },
      "outputs": [],
      "source": [
        "def plot_log_function(history):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.plot(history.history['loss']) # tb\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "r4eQlg6TGit5"
      },
      "outputs": [],
      "source": [
        "def random_transform(image):\n",
        "    choice = random.randint(0, 5)\n",
        "\n",
        "    rows, cols, _ = image.shape\n",
        "\n",
        "    if choice == 0: # Translation\n",
        "        tx, ty = random.randint(-20, 20), random.randint(-20, 20)\n",
        "        M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
        "        return cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "    elif choice == 1: # Rotation\n",
        "        angle = random.randint(-30, 30)\n",
        "        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
        "        return cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "    elif choice == 2: # Scaling\n",
        "        scale_factor = random.uniform(0.8, 1.2)\n",
        "        new_rows, new_cols = int(rows * scale_factor), int(cols * scale_factor)\n",
        "        return cv2.resize(image, (new_cols, new_rows))\n",
        "\n",
        "    elif choice == 3: # Skewing\n",
        "        pts1 = np.float32([[5,5],[20,5],[5,20]])\n",
        "        pt1 = 5+10*np.random.uniform()-10/2\n",
        "        pt2 = 20+10*np.random.uniform()-10/2\n",
        "        pts2 = np.float32([[pt1,5],[pt2,pt1],[5,pt2]])\n",
        "        M = cv2.getAffineTransform(pts1,pts2)\n",
        "        return cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "    elif choice == 4: # Perspective distortion\n",
        "        pts1 = np.float32([[5,5],[20,5],[5,20],[20,20]])\n",
        "        pts2 = np.float32([[0,0],[20,5],[5,20],[20,20]])\n",
        "        M = cv2.getPerspectiveTransform(pts1,pts2)\n",
        "        return cv2.warpPerspective(image, M, (cols, rows))\n",
        "\n",
        "    else: # Pincushion distortion\n",
        "        distortion = np.float32([1, 1, 0, 0])\n",
        "        camera_matrix = np.eye(3)\n",
        "        return cv2.undistort(image, camera_matrix, distortion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gAZLIzJRGit7"
      },
      "outputs": [],
      "source": [
        "def get_transformed_test_images(test_images):\n",
        "    transformed_test_images = []\n",
        "    for img in test_images:\n",
        "        transformed_img = random_transform(img)\n",
        "        transformed_test_images.append(transformed_img)\n",
        "\n",
        "    # resizing transformed_test_images into (32, 32)\n",
        "    new_shape = (32, 32)\n",
        "    transformed_test_images = np.array([cv2.resize(img, new_shape).reshape(32, 32, 1) for img in transformed_test_images])\n",
        "\n",
        "    # Checking for shape consistency\n",
        "\n",
        "    good_shape = test_images[0].shape\n",
        "    for i, img in enumerate(transformed_test_images):\n",
        "        if img.shape != good_shape:\n",
        "            print(f\"Inconsistent shape at index {i}: expected {good_shape}, but got {img.shape}\")\n",
        "    return transformed_test_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KizrZqGGit8"
      },
      "source": [
        "# 1 mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KgtBjt-RGit9",
        "outputId": "cf9abd94-3c1b-43dc-d6b4-092043de68f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Shuffle the training data and labels\n",
        "shuffle_index_train = np.random.permutation(len(train_images))\n",
        "train_images = train_images[shuffle_index_train]\n",
        "train_labels = train_labels[shuffle_index_train]\n",
        "\n",
        "# Shuffle the testing data and labels\n",
        "shuffle_index_test = np.random.permutation(len(test_images))\n",
        "test_images = test_images[shuffle_index_test]\n",
        "test_labels = test_labels[shuffle_index_test]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ayt-GU0rsdSh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gLyffGqOGit-"
      },
      "outputs": [],
      "source": [
        "# Preprocess images\n",
        "new_shape = (32, 32)\n",
        "train_images = np.array([cv2.resize(img, new_shape) for img in train_images])\n",
        "test_images = np.array([cv2.resize(img, new_shape) for img in test_images])\n",
        "\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "train_images = train_images[..., tf.newaxis].astype(\"float32\")\n",
        "test_images = test_images[..., tf.newaxis].astype(\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2EKFGVTGiuB",
        "outputId": "efa91c9f-c83b-4e14-c0a4-9cf1622db519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images size:  (54000, 32, 32, 1)  and val_images size:  (6000, 32, 32, 1)\n",
            "train_labels size:  (54000,)  and val_labels size:  (6000,)\n"
          ]
        }
      ],
      "source": [
        "# creating validation images val_images\n",
        "val_size = int(len(train_labels)*0.10)\n",
        "\n",
        "train_images , val_images= train_images[val_size:], train_images[:val_size]\n",
        "print(\"train_images size: \", train_images.shape, \" and val_images size: \", val_images.shape)\n",
        "\n",
        "train_labels , val_labels= train_labels[val_size:], train_labels[:val_size]\n",
        "print(\"train_labels size: \", train_labels.shape, \" and val_labels size: \", val_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJFxwUorGiuC"
      },
      "source": [
        "## 1-1 Vision Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "j-UH-BkQGiuD"
      },
      "outputs": [],
      "source": [
        "# Build the ViT model\n",
        "\n",
        "def create_vit_model(input_shape = (*new_shape, 1),  patch_size = 4, num_heads = 12, projection_dim = 32, num_transformer_layers = 12, mlp_head_units = [64, 32]):\n",
        "\n",
        "    num_patches = (new_shape[0] // patch_size) * (new_shape[1] // patch_size)\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(3, (3, 3), padding=\"same\")(inputs)  # Convert to 3 channels\n",
        "    x = tf.keras.layers.Rescaling(1.0 / 255)(x)  # Rescale\n",
        "    x = tf.keras.layers.Conv2D(32, (patch_size, patch_size), strides=patch_size)(x)\n",
        "    x = tf.keras.layers.Reshape((num_patches, 32))(x)\n",
        "\n",
        "    for _ in range(num_transformer_layers):\n",
        "        x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        attention_output = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        x2 = tf.keras.layers.Add()([attention_output, x])\n",
        "        x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = tf.keras.layers.Conv1D(64, 2, padding=\"same\", activation=\"relu\")(x3)\n",
        "        x3 = tf.keras.layers.Dropout(0.1)(x3)\n",
        "        x3 = tf.keras.layers.Conv1D(32, 2, padding=\"same\")(x3)\n",
        "        x = tf.keras.layers.Add()([x3, x2])\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    for dim in mlp_head_units:\n",
        "        x = tf.keras.layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = tf.keras.layers.Dropout(0.1)(x)\n",
        "    outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from vit_keras import vit\n",
        "def build_vit_model(input_shape, num_classes=3):\n",
        "\n",
        "  input_layer = Input(input_shape)\n",
        "  replicated_channels = Concatenate(axis=-1)([input_layer] * 3)\n",
        "\n",
        "  vit_model = vit.vit_b32(\n",
        "      image_size=input_shape[0],\n",
        "      activation='softmax',\n",
        "      pretrained=True,\n",
        "      include_top=True,\n",
        "      pretrained_top=False,\n",
        "      classes=num_classes)(replicated_channels)\n",
        "\n",
        "  return Model(inputs=input_layer, outputs=vit_model)"
      ],
      "metadata": {
        "id": "VvKldWcByBtw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vS-9t3jJGiuF",
        "outputId": "426198bc-2fa5-4e33-ea5e-a023bdfe75b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-B_32_imagenet21k+imagenet2012.npz\n",
            "353253686/353253686 [==============================] - 22s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/vit_keras/utils.py:81: UserWarning: Resizing position embeddings from 12, 12 to 1, 1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-25fe928ab52e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model = create_vit_model(input_shape = (*new_shape, 1),  patch_size = 4, num_heads = 2, projection_dim = 32, num_transformer_layers = 32, mlp_head_units = [64, 32])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-f55fca6515dc>\u001b[0m in \u001b[0;36mbuild_vit_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mreplicated_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   vit_model = vit.vit_b32(\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    254\u001b[0m                     \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0;34m\"is incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"vit-b32\" (type Functional).\n\nInput 0 of layer \"embedding\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 32, 96)\n\nCall arguments received by layer \"vit-b32\" (type Functional):\n  • inputs=tf.Tensor(shape=(None, 32, 96), dtype=float32)\n  • training=None\n  • mask=None"
          ]
        }
      ],
      "source": [
        "# model = create_vit_model(input_shape = (*new_shape, 1),  patch_size = 4, num_heads = 2, projection_dim = 32, num_transformer_layers = 32, mlp_head_units = [64, 32])\n",
        "model = build_vit_model(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ5uD8dVGiuG"
      },
      "outputs": [],
      "source": [
        "hyperparameters={\n",
        "    \"batch_size\": 32,\n",
        "    \"epochs\": 100,\n",
        "    \"optimizer\":\"adam\",\n",
        "    'early_stopping_patience':10,\n",
        "    \"learning_rate\":0.1\n",
        "}\n",
        "def train_individual_model(model, train_images, train_labels, val_data, batch_size=hyperparameters['batch_size'], epochs=hyperparameters['epochs'], patience =hyperparameters['early_stopping_patience'], learning_rate= hyperparameters[\"learning_rate\"]):\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "\n",
        "                  metrics=['accuracy'])\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience= patience, verbose=1, restore_best_weights=True)\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(train_images,train_labels, validation_data=val_data, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
        "    end_time = time.time()\n",
        "    print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    # Using history to print training metrics\n",
        "    print(\"\\nTraining Metrics:\")\n",
        "    print(f\"Loss: {history.history['loss'][-1]}\")\n",
        "    print(f\"Accuracy: {history.history['accuracy'][-1]}\")\n",
        "\n",
        "    # Using history to print validation metrics\n",
        "    print(\"\\nValidation Metrics:\")\n",
        "    print(f\"Loss: {history.history['val_loss'][-1]}\")\n",
        "    print(f\"Accuracy: {history.history['val_accuracy'][-1]}\")\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history= train_individual_model(model, train_images,train_labels, val_data = (val_images, val_labels), batch_size=hyperparameters['batch_size'], epochs=hyperparameters['epochs'], patience =hyperparameters['early_stopping_patience'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhUU6HmoM6O6",
        "outputId": "74a48d2e-fd51-46e1-f06c-58d2acf0c040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "106/106 [==============================] - 118s 161ms/step - loss: 75.6452 - accuracy: 0.1037 - val_loss: 2.3016 - val_accuracy: 0.1090\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 14s 130ms/step - loss: 2.3020 - accuracy: 0.1101 - val_loss: 2.3032 - val_accuracy: 0.1090\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 14s 129ms/step - loss: 2.3022 - accuracy: 0.1081 - val_loss: 2.3033 - val_accuracy: 0.1090\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 14s 128ms/step - loss: 2.3055 - accuracy: 0.1099 - val_loss: 2.3022 - val_accuracy: 0.1090\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 14s 128ms/step - loss: 2.3026 - accuracy: 0.1078 - val_loss: 2.3053 - val_accuracy: 0.1053\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 13s 127ms/step - loss: 2.3074 - accuracy: 0.1086 - val_loss: 2.3055 - val_accuracy: 0.1090\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 14s 128ms/step - loss: 2.3598 - accuracy: 0.1080 - val_loss: 2.3037 - val_accuracy: 0.1090\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 14s 129ms/step - loss: 2.4052 - accuracy: 0.1077 - val_loss: 2.3050 - val_accuracy: 0.0982\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 14s 131ms/step - loss: 2.3031 - accuracy: 0.1095 - val_loss: 2.3052 - val_accuracy: 0.0982\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 14s 130ms/step - loss: 2.3039 - accuracy: 0.1079 - val_loss: 2.3031 - val_accuracy: 0.0982\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 15s 137ms/step - loss: 2.3036 - accuracy: 0.1068 - val_loss: 2.3026 - val_accuracy: 0.1055\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - ETA: 0s - loss: 2.3036 - accuracy: 0.1064Restoring model weights from the end of the best epoch: 2.\n",
            "106/106 [==============================] - 14s 130ms/step - loss: 2.3036 - accuracy: 0.1064 - val_loss: 2.3039 - val_accuracy: 0.1090\n",
            "Epoch 12: early stopping\n",
            "Training time: 269.49 seconds\n",
            "\n",
            "Training Metrics:\n",
            "Loss: 2.3035809993743896\n",
            "Accuracy: 0.1063888892531395\n",
            "\n",
            "Validation Metrics:\n",
            "Loss: 2.303925037384033\n",
            "Accuracy: 0.10899999737739563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99wgN40YGiuJ"
      },
      "outputs": [],
      "source": [
        "#saving model\n",
        "path = os.path.join(\"/content/drive/My Drive/ML_researchexperiments\",'vit_mnist', 'model')\n",
        "save_model(model, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olNNm8lyGiuJ"
      },
      "outputs": [],
      "source": [
        "#checking the performance on taining_data\n",
        "plot_log_function(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opFeAG7QGiuK"
      },
      "outputs": [],
      "source": [
        "history_path = os.path.join(os.path.dirname(os.getcwd()),'experiments','multi_headed_attention_mnist_dataset', 'history.log')\n",
        "save_model_logs(history,history_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcow7MVOGiuL"
      },
      "outputs": [],
      "source": [
        "path = os.path.join(os.path.dirname(os.getcwd()),'experiments','multi_headed_attention_mnist_dataset', 'model.pkl')\n",
        "\n",
        "model = load_model(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1TvBzL3GiuM",
        "outputId": "c19d8870-4891-4843-b5e5-ec6c58058eab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'Vision Transformer', 'hyperparameters': {'learning_rate': 0.001, 'batch_size': 32, 'epochs': 12, 'optimizer': 'adam', 'early_stopping_patience': 3}, 'model_architecture': {'class_name': 'Functional', 'config': {'name': 'model', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_input_shape': [None, 32, 32, 1], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_1'}, 'registered_name': None, 'name': 'input_1', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 3, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 32, 32, 1]}, 'name': 'conv2d', 'inbound_nodes': [[['input_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Rescaling', 'config': {'name': 'rescaling', 'trainable': True, 'dtype': 'float32', 'scale': 0.00392156862745098, 'offset': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 32, 32, 3]}, 'name': 'rescaling', 'inbound_nodes': [[['conv2d', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': [4, 4], 'strides': [4, 4], 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 32, 32, 3]}, 'name': 'conv2d_1', 'inbound_nodes': [[['rescaling', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Reshape', 'config': {'name': 'reshape', 'trainable': True, 'dtype': 'float32', 'target_shape': [64, 32]}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 8, 32]}, 'name': 'reshape', 'inbound_nodes': [[['conv2d_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'LayerNormalization', 'config': {'name': 'layer_normalization', 'trainable': True, 'dtype': 'float32', 'axis': [2], 'epsilon': 1e-06, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'layer_normalization', 'inbound_nodes': [[['reshape', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'MultiHeadAttention', 'config': {'name': 'multi_head_attention', 'trainable': True, 'dtype': 'float32', 'num_heads': 2, 'key_dim': 32, 'value_dim': 32, 'dropout': 0.1, 'use_bias': True, 'output_shape': None, 'attention_axes': [1], 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None, 'query_shape': [None, 64, 32], 'key_shape': [None, 64, 32], 'value_shape': [None, 64, 32]}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'multi_head_attention', 'inbound_nodes': [[['layer_normalization', 0, 0, {'value': ['layer_normalization', 0, 0]}]]]}, {'module': 'keras.layers', 'class_name': 'Add', 'config': {'name': 'add', 'trainable': True, 'dtype': 'float32'}, 'registered_name': None, 'build_config': {'input_shape': [[None, 64, 32], [None, 64, 32]]}, 'name': 'add', 'inbound_nodes': [[['multi_head_attention', 0, 0, {}], ['reshape', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'LayerNormalization', 'config': {'name': 'layer_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': [2], 'epsilon': 1e-06, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'layer_normalization_1', 'inbound_nodes': [[['add', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': [2], 'strides': [1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'conv1d', 'inbound_nodes': [[['layer_normalization_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64]}, 'name': 'dropout', 'inbound_nodes': [[['conv1d', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d_1', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': [2], 'strides': [1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64]}, 'name': 'conv1d_1', 'inbound_nodes': [[['dropout', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Add', 'config': {'name': 'add_1', 'trainable': True, 'dtype': 'float32'}, 'registered_name': None, 'build_config': {'input_shape': [[None, 64, 32], [None, 64, 32]]}, 'name': 'add_1', 'inbound_nodes': [[['conv1d_1', 0, 0, {}], ['add', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'LayerNormalization', 'config': {'name': 'layer_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': [2], 'epsilon': 1e-06, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'layer_normalization_2', 'inbound_nodes': [[['add_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'MultiHeadAttention', 'config': {'name': 'multi_head_attention_1', 'trainable': True, 'dtype': 'float32', 'num_heads': 2, 'key_dim': 32, 'value_dim': 32, 'dropout': 0.1, 'use_bias': True, 'output_shape': None, 'attention_axes': [1], 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None, 'query_shape': [None, 64, 32], 'key_shape': [None, 64, 32], 'value_shape': [None, 64, 32]}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'multi_head_attention_1', 'inbound_nodes': [[['layer_normalization_2', 0, 0, {'value': ['layer_normalization_2', 0, 0]}]]]}, {'module': 'keras.layers', 'class_name': 'Add', 'config': {'name': 'add_2', 'trainable': True, 'dtype': 'float32'}, 'registered_name': None, 'build_config': {'input_shape': [[None, 64, 32], [None, 64, 32]]}, 'name': 'add_2', 'inbound_nodes': [[['multi_head_attention_1', 0, 0, {}], ['add_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'LayerNormalization', 'config': {'name': 'layer_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': [2], 'epsilon': 1e-06, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'layer_normalization_3', 'inbound_nodes': [[['add_2', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d_2', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': [2], 'strides': [1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'conv1d_2', 'inbound_nodes': [[['layer_normalization_3', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64]}, 'name': 'dropout_1', 'inbound_nodes': [[['conv1d_2', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': [2], 'strides': [1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64]}, 'name': 'conv1d_3', 'inbound_nodes': [[['dropout_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Add', 'config': {'name': 'add_3', 'trainable': True, 'dtype': 'float32'}, 'registered_name': None, 'build_config': {'input_shape': [[None, 64, 32], [None, 64, 32]]}, 'name': 'add_3', 'inbound_nodes': [[['conv1d_3', 0, 0, {}], ['add_2', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'GlobalAveragePooling1D', 'config': {'name': 'global_average_pooling1d', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last', 'keepdims': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'global_average_pooling1d', 'inbound_nodes': [[['add_3', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 64, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 32]}, 'name': 'dense', 'inbound_nodes': [[['global_average_pooling1d', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64]}, 'name': 'dropout_2', 'inbound_nodes': [[['dense', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 32, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64]}, 'name': 'dense_1', 'inbound_nodes': [[['dropout_2', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 32]}, 'name': 'dropout_3', 'inbound_nodes': [[['dense_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 32]}, 'name': 'dense_2', 'inbound_nodes': [[['dropout_3', 0, 0, {}]]]}], 'input_layers': [['input_1', 0, 0]], 'output_layers': [['dense_2', 0, 0]]}, 'keras_version': '2.13.1', 'backend': 'tensorflow'}}\n"
          ]
        }
      ],
      "source": [
        "# saving model architecture and hypermarameters\n",
        "model_info = {\n",
        "    \"model_name\": \"Vision Transformer\"\n",
        "}\n",
        "model_info[\"hyperparameters\"] = hyperparameters\n",
        "model_info[\"model_architecture\"] = model.to_json()\n",
        "model_info[\"model_architecture\"]  = json.loads(model_info[\"model_architecture\"] )\n",
        "\n",
        "path = os.path.join(os.path.dirname(os.getcwd()),'experiments','multi_headed_attention_mnist_dataset', 'mode_architecture.json')\n",
        "dump_json(model_info, path )\n",
        "print(model_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYkHMtFXGiuN"
      },
      "outputs": [],
      "source": [
        "transformed_test_images= get_transformed_test_images(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXuvne_5GiuO",
        "outputId": "0e001b6d-ca9a-44c0-fef5-64df74fdac4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 47s 34ms/step - loss: 0.1723 - accuracy: 0.9430\n",
            "1407/1407 [==============================] - 39s 28ms/step\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.1866 - accuracy: 0.9435\n",
            "469/469 [==============================] - 14s 31ms/step\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.1858 - accuracy: 0.9429\n",
            "313/313 [==============================] - 9s 29ms/step\n",
            "313/313 [==============================] - 9s 29ms/step - loss: 3.3355 - accuracy: 0.6694\n",
            "313/313 [==============================] - 9s 29ms/step\n",
            "{'model_name': 'Vision Transformer', 'train_images_performance_metrics': {'accuracy': 0.9430444240570068, 'precision': 0.9436927070787323, 'recall': 0.9420877265489679, 'f1_score': 0.9422721891708056}, 'validation_images_performance_metrics': {'accuracy': 0.9435333609580994, 'precision': 0.9438024712517473, 'recall': 0.9425949696819353, 'f1_score': 0.9427020690781334}, 'test_images_performance_metrics': {'accuracy': 0.9429000020027161, 'precision': 0.9440102443234146, 'recall': 0.9418122581187565, 'f1_score': 0.9421103523277411}, 'transformed_test_images_performance_metrics': {'accuracy': 0.6693999767303467, 'precision': 0.7721902514267633, 'recall': 0.6645088858253737, 'f1_score': 0.6914443995671273}}\n"
          ]
        }
      ],
      "source": [
        "#saving model performance metrics\n",
        "model_performance_metrics = {\n",
        "    \"model_name\": \"Vision Transformer\"\n",
        "}\n",
        "model_performance_metrics[\"train_images_performance_metrics\"] = get_model_performance_metrics(model,train_images, train_labels)\n",
        "model_performance_metrics[\"validation_images_performance_metrics\"] = get_model_performance_metrics(model,val_images, val_labels)\n",
        "model_performance_metrics[\"test_images_performance_metrics\"] = get_model_performance_metrics(model, test_images, test_labels)\n",
        "model_performance_metrics[\"transformed_test_images_performance_metrics\"] = get_model_performance_metrics(model, transformed_test_images, test_labels)\n",
        "\n",
        "\n",
        "path = os.path.join(os.path.dirname(os.getcwd()),'experiments','multi_headed_attention_mnist_dataset', 'mode_performance_metrics.json')\n",
        "dump_json(model_performance_metrics, path)\n",
        "print(model_performance_metrics)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}