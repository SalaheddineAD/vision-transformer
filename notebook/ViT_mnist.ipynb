{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SalaheddineAD/vision-transformer/blob/main/notebook/ViT_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDMEQya6Gitc",
        "outputId": "089cb76d-e139-4662-d857-d0404d39a1f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (0.3.7)\n"
          ]
        }
      ],
      "source": [
        "pip install dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTO1lYk1Gitm",
        "outputId": "eefaa16d-94d6-4c17-bdce-e38639495200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (2.13.3)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Qz7SxxMqGitn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import time\n",
        "import logging\n",
        "import json\n",
        "import os\n",
        "import dill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERtFUHCAGitr"
      },
      "source": [
        "### Enable tensorflow on gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB3iMNLqGitu",
        "outputId": "649c474d-a5ba-40df-e93f-38a99a59d961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 15 15:41:17 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBpicbR0Gitv",
        "outputId": "6438d19f-4246-48a0-d6e5-9591e7a668a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: gpu_enabled: command not found\n"
          ]
        }
      ],
      "source": [
        "!gpu_enabled = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob3YtveoGitx",
        "outputId": "920cc845-05db-4e89-ad1f-8e29aeef79f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "print(tf.__version__)\n",
        "# ! pip install tensorflow==2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WlIc5GKGity",
        "outputId": "dc0aedd6-0b3d-4edb-cc46-22af5c2622ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check the number of available GPUs (optional)\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "# Set the GPU as the default device\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "\n",
        "# Now, TensorFlow will use the GPU for all operations by default\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zGLSo_xafDkk",
        "outputId": "4ec008ab-4790-4469-b48c-4afd1ec91956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0V1H__L8Git0"
      },
      "outputs": [],
      "source": [
        "def dump_json(data, json_file_path):\n",
        "    with open(json_file_path, 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "def load_json(json_file_path):\n",
        "    with open(json_file_path, 'r') as json_file:\n",
        "        loaded_data = json.load(json_file)\n",
        "    return loaded_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LpsWdb-GGit1"
      },
      "outputs": [],
      "source": [
        "def save_model(model, file_path):\n",
        "    os.makedirs(file_path, exist_ok=True)\n",
        "    model.save(file_path)\n",
        "\n",
        "\n",
        "def load_model(file_path):\n",
        "    loaded_model = tf.keras.models.load_model(file_path)\n",
        "    return loaded_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PpXjKKLLGit2"
      },
      "outputs": [],
      "source": [
        "def get_model_performance_metrics(model, images, labels):\n",
        "    # Evaluating the model\n",
        "    loss, accuracy = model.evaluate(images, labels)\n",
        "\n",
        "    # Getting Precision, Recall, and F1 Score\n",
        "    y_pred = model.predict(images)\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    precision, recall, f1_score, _ = precision_recall_fscore_support(labels, y_pred_labels, average='macro')\n",
        "    performance = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1_score\n",
        "    }\n",
        "    return performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iaRweEIXGit3"
      },
      "outputs": [],
      "source": [
        "def save_model_logs(history,history_path):\n",
        "    # saving logs\n",
        "    logging.basicConfig(filename= history_path, level=logging.INFO)\n",
        "\n",
        "    # Log training history\n",
        "    for epoch, (loss, val_loss) in enumerate(zip(history.history['loss'], history.history['val_loss'])):\n",
        "        logging.info(f\"Epoch {epoch + 1}, Loss: {loss}, Val Loss {val_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IEJfyA2vGit4"
      },
      "outputs": [],
      "source": [
        "def plot_log_function(history):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.plot(history.history['loss']) # tb\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "r4eQlg6TGit5"
      },
      "outputs": [],
      "source": [
        "def random_transform(image):\n",
        "    choice = random.randint(0, 5)\n",
        "\n",
        "    rows, cols, _ = image.shape\n",
        "\n",
        "    if choice == 0: # Translation\n",
        "        tx, ty = random.randint(-20, 20), random.randint(-20, 20)\n",
        "        M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
        "        return cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "    elif choice == 1: # Rotation\n",
        "        angle = random.randint(-30, 30)\n",
        "        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
        "        return cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "    elif choice == 2: # Scaling\n",
        "        scale_factor = random.uniform(0.8, 1.2)\n",
        "        new_rows, new_cols = int(rows * scale_factor), int(cols * scale_factor)\n",
        "        return cv2.resize(image, (new_cols, new_rows))\n",
        "\n",
        "    elif choice == 3: # Skewing\n",
        "        pts1 = np.float32([[5,5],[20,5],[5,20]])\n",
        "        pt1 = 5+10*np.random.uniform()-10/2\n",
        "        pt2 = 20+10*np.random.uniform()-10/2\n",
        "        pts2 = np.float32([[pt1,5],[pt2,pt1],[5,pt2]])\n",
        "        M = cv2.getAffineTransform(pts1,pts2)\n",
        "        return cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "    elif choice == 4: # Perspective distortion\n",
        "        pts1 = np.float32([[5,5],[20,5],[5,20],[20,20]])\n",
        "        pts2 = np.float32([[0,0],[20,5],[5,20],[20,20]])\n",
        "        M = cv2.getPerspectiveTransform(pts1,pts2)\n",
        "        return cv2.warpPerspective(image, M, (cols, rows))\n",
        "\n",
        "    else: # Pincushion distortion\n",
        "        distortion = np.float32([1, 1, 0, 0])\n",
        "        camera_matrix = np.eye(3)\n",
        "        return cv2.undistort(image, camera_matrix, distortion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gAZLIzJRGit7"
      },
      "outputs": [],
      "source": [
        "def get_transformed_test_images(test_images):\n",
        "    transformed_test_images = []\n",
        "    for img in test_images:\n",
        "        transformed_img = random_transform(img)\n",
        "        transformed_test_images.append(transformed_img)\n",
        "\n",
        "    # resizing transformed_test_images into (32, 32)\n",
        "    new_shape = (32, 32)\n",
        "    transformed_test_images = np.array([cv2.resize(img, new_shape).reshape(32, 32, 1) for img in transformed_test_images])\n",
        "\n",
        "    # Checking for shape consistency\n",
        "\n",
        "    good_shape = test_images[0].shape\n",
        "    for i, img in enumerate(transformed_test_images):\n",
        "        if img.shape != good_shape:\n",
        "            print(f\"Inconsistent shape at index {i}: expected {good_shape}, but got {img.shape}\")\n",
        "    return transformed_test_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KizrZqGGit8"
      },
      "source": [
        "# 1 mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "KgtBjt-RGit9"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Shuffle the training data and labels\n",
        "shuffle_index_train = np.random.permutation(len(train_images))\n",
        "train_images = train_images[shuffle_index_train]\n",
        "train_labels = train_labels[shuffle_index_train]\n",
        "\n",
        "# Shuffle the testing data and labels\n",
        "shuffle_index_test = np.random.permutation(len(test_images))\n",
        "test_images = test_images[shuffle_index_test]\n",
        "test_labels = test_labels[shuffle_index_test]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ayt-GU0rsdSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "gLyffGqOGit-"
      },
      "outputs": [],
      "source": [
        "# Preprocess images\n",
        "new_shape = (32, 32)\n",
        "train_images = np.array([cv2.resize(img, new_shape) for img in train_images])\n",
        "test_images = np.array([cv2.resize(img, new_shape) for img in test_images])\n",
        "\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "train_images = train_images[..., tf.newaxis].astype(\"float32\")\n",
        "test_images = test_images[..., tf.newaxis].astype(\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2EKFGVTGiuB",
        "outputId": "47169f98-82ad-4477-a7ee-34b42057a033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images size:  (54000, 32, 32, 1)  and val_images size:  (6000, 32, 32, 1)\n",
            "train_labels size:  (54000,)  and val_labels size:  (6000,)\n"
          ]
        }
      ],
      "source": [
        "# creating validation images val_images\n",
        "val_size = int(len(train_labels)*0.10)\n",
        "\n",
        "train_images , val_images= train_images[val_size:], train_images[:val_size]\n",
        "print(\"train_images size: \", train_images.shape, \" and val_images size: \", val_images.shape)\n",
        "\n",
        "train_labels , val_labels= train_labels[val_size:], train_labels[:val_size]\n",
        "print(\"train_labels size: \", train_labels.shape, \" and val_labels size: \", val_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJFxwUorGiuC"
      },
      "source": [
        "## 1-1 Vision Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "j-UH-BkQGiuD"
      },
      "outputs": [],
      "source": [
        "# Build the ViT model\n",
        "\n",
        "def create_vit_model(input_shape = (*new_shape, 1),  patch_size = 4, num_heads = 12, projection_dim = 32, num_transformer_layers = 12, mlp_head_units = [64, 32]):\n",
        "\n",
        "    num_patches = (new_shape[0] // patch_size) * (new_shape[1] // patch_size)\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(3, (3, 3), padding=\"same\")(inputs)  # Convert to 3 channels\n",
        "    x = tf.keras.layers.Rescaling(1.0 / 255)(x)  # Rescale\n",
        "    x = tf.keras.layers.Conv2D(32, (patch_size, patch_size), strides=patch_size)(x)\n",
        "    x = tf.keras.layers.Reshape((num_patches, 32))(x)\n",
        "\n",
        "    for _ in range(num_transformer_layers):\n",
        "        x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        attention_output = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        x2 = tf.keras.layers.Add()([attention_output, x])\n",
        "        x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = tf.keras.layers.Conv1D(64, 2, padding=\"same\", activation=\"relu\")(x3)\n",
        "        x3 = tf.keras.layers.Dropout(0.1)(x3)\n",
        "        x3 = tf.keras.layers.Conv1D(32, 2, padding=\"same\")(x3)\n",
        "        x = tf.keras.layers.Add()([x3, x2])\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    for dim in mlp_head_units:\n",
        "        x = tf.keras.layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = tf.keras.layers.Dropout(0.1)(x)\n",
        "    outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "vS-9t3jJGiuF"
      },
      "outputs": [],
      "source": [
        "model = create_vit_model(input_shape = (*new_shape, 1),  patch_size = 4, num_heads = 2, projection_dim = 32, num_transformer_layers = 32, mlp_head_units = [64, 32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "HZ5uD8dVGiuG"
      },
      "outputs": [],
      "source": [
        "hyperparameters={\n",
        "    \"batch_size\": 32,\n",
        "    \"epochs\": 100,\n",
        "    \"optimizer\":\"adam\",\n",
        "    'early_stopping_patience':10,\n",
        "    \"learning_rate\":0.1\n",
        "}\n",
        "def train_individual_model(model, train_images, train_labels, val_data, batch_size=hyperparameters['batch_size'], epochs=hyperparameters['epochs'], patience =hyperparameters['early_stopping_patience'], learning_rate= hyperparameters[\"learning_rate\"]):\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "\n",
        "                  metrics=['accuracy'])\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience= patience, verbose=1, restore_best_weights=True)\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(train_images,train_labels, validation_data=val_data, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
        "    end_time = time.time()\n",
        "    print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    # Using history to print training metrics\n",
        "    print(\"\\nTraining Metrics:\")\n",
        "    print(f\"Loss: {history.history['loss'][-1]}\")\n",
        "    print(f\"Accuracy: {history.history['accuracy'][-1]}\")\n",
        "\n",
        "    # Using history to print validation metrics\n",
        "    print(\"\\nValidation Metrics:\")\n",
        "    print(f\"Loss: {history.history['val_loss'][-1]}\")\n",
        "    print(f\"Accuracy: {history.history['val_accuracy'][-1]}\")\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history= train_individual_model(model, train_images,train_labels, val_data = (val_images, val_labels), batch_size=hyperparameters['batch_size'], epochs=hyperparameters['epochs'], patience =hyperparameters['early_stopping_patience'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhUU6HmoM6O6",
        "outputId": "74a48d2e-fd51-46e1-f06c-58d2acf0c040"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "106/106 [==============================] - 118s 161ms/step - loss: 75.6452 - accuracy: 0.1037 - val_loss: 2.3016 - val_accuracy: 0.1090\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 14s 130ms/step - loss: 2.3020 - accuracy: 0.1101 - val_loss: 2.3032 - val_accuracy: 0.1090\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 14s 129ms/step - loss: 2.3022 - accuracy: 0.1081 - val_loss: 2.3033 - val_accuracy: 0.1090\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 14s 128ms/step - loss: 2.3055 - accuracy: 0.1099 - val_loss: 2.3022 - val_accuracy: 0.1090\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 14s 128ms/step - loss: 2.3026 - accuracy: 0.1078 - val_loss: 2.3053 - val_accuracy: 0.1053\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 13s 127ms/step - loss: 2.3074 - accuracy: 0.1086 - val_loss: 2.3055 - val_accuracy: 0.1090\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 14s 128ms/step - loss: 2.3598 - accuracy: 0.1080 - val_loss: 2.3037 - val_accuracy: 0.1090\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 14s 129ms/step - loss: 2.4052 - accuracy: 0.1077 - val_loss: 2.3050 - val_accuracy: 0.0982\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 14s 131ms/step - loss: 2.3031 - accuracy: 0.1095 - val_loss: 2.3052 - val_accuracy: 0.0982\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 14s 130ms/step - loss: 2.3039 - accuracy: 0.1079 - val_loss: 2.3031 - val_accuracy: 0.0982\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 15s 137ms/step - loss: 2.3036 - accuracy: 0.1068 - val_loss: 2.3026 - val_accuracy: 0.1055\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - ETA: 0s - loss: 2.3036 - accuracy: 0.1064Restoring model weights from the end of the best epoch: 2.\n",
            "106/106 [==============================] - 14s 130ms/step - loss: 2.3036 - accuracy: 0.1064 - val_loss: 2.3039 - val_accuracy: 0.1090\n",
            "Epoch 12: early stopping\n",
            "Training time: 269.49 seconds\n",
            "\n",
            "Training Metrics:\n",
            "Loss: 2.3035809993743896\n",
            "Accuracy: 0.1063888892531395\n",
            "\n",
            "Validation Metrics:\n",
            "Loss: 2.303925037384033\n",
            "Accuracy: 0.10899999737739563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99wgN40YGiuJ"
      },
      "outputs": [],
      "source": [
        "#saving model\n",
        "path = os.path.join(\"/content/drive/My Drive/ML_researchexperiments\",'vit_mnist', 'model')\n",
        "save_model(model, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olNNm8lyGiuJ"
      },
      "outputs": [],
      "source": [
        "#checking the performance on taining_data\n",
        "plot_log_function(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opFeAG7QGiuK"
      },
      "outputs": [],
      "source": [
        "history_path = os.path.join(os.path.dirname(os.getcwd()),'experiments','multi_headed_attention_mnist_dataset', 'history.log')\n",
        "save_model_logs(history,history_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcow7MVOGiuL"
      },
      "outputs": [],
      "source": [
        "path = os.path.join(os.path.dirname(os.getcwd()),'experiments','multi_headed_attention_mnist_dataset', 'model.pkl')\n",
        "\n",
        "model = load_model(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1TvBzL3GiuM",
        "outputId": "c19d8870-4891-4843-b5e5-ec6c58058eab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'Vision Transformer', 'hyperparameters': {'learning_rate': 0.001, 'batch_size': 32, 'epochs': 12, 'optimizer': 'adam', 'early_stopping_patience': 3}, 'model_architecture': {'class_name': 'Functional', 'config': {'name': 'model', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_input_shape': [None, 32, 32, 1], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_1'}, 'registered_name': None, 'name': 'input_1', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 3, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 32, 32, 1]}, 'name': 'conv2d', 'inbound_nodes': [[['input_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Rescaling', 'config': {'name': 'rescaling', 'trainable': True, 'dtype': 'float32', 'scale': 0.00392156862745098, 'offset': 0.0}, 'registered_name': None, 'build_config': {'input_shape': [None, 32, 32, 3]}, 'name': 'rescaling', 'inbound_nodes': [[['conv2d', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': [4, 4], 'strides': [4, 4], 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 32, 32, 3]}, 'name': 'conv2d_1', 'inbound_nodes': [[['rescaling', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Reshape', 'config': {'name': 'reshape', 'trainable': True, 'dtype': 'float32', 'target_shape': [64, 32]}, 'registered_name': None, 'build_config': {'input_shape': [None, 8, 8, 32]}, 'name': 'reshape', 'inbound_nodes': [[['conv2d_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'LayerNormalization', 'config': {'name': 'layer_normalization', 'trainable': True, 'dtype': 'float32', 'axis': [2], 'epsilon': 1e-06, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'layer_normalization', 'inbound_nodes': [[['reshape', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'MultiHeadAttention', 'config': {'name': 'multi_head_attention', 'trainable': True, 'dtype': 'float32', 'num_heads': 2, 'key_dim': 32, 'value_dim': 32, 'dropout': 0.1, 'use_bias': True, 'output_shape': None, 'attention_axes': [1], 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None, 'query_shape': [None, 64, 32], 'key_shape': [None, 64, 32], 'value_shape': [None, 64, 32]}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'multi_head_attention', 'inbound_nodes': [[['layer_normalization', 0, 0, {'value': ['layer_normalization', 0, 0]}]]]}, {'module': 'keras.layers', 'class_name': 'Add', 'config': {'name': 'add', 'trainable': True, 'dtype': 'float32'}, 'registered_name': None, 'build_config': {'input_shape': [[None, 64, 32], [None, 64, 32]]}, 'name': 'add', 'inbound_nodes': [[['multi_head_attention', 0, 0, {}], ['reshape', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'LayerNormalization', 'config': {'name': 'layer_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': [2], 'epsilon': 1e-06, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'layer_normalization_1', 'inbound_nodes': [[['add', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': [2], 'strides': [1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'conv1d', 'inbound_nodes': [[['layer_normalization_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64]}, 'name': 'dropout', 'inbound_nodes': [[['conv1d', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d_1', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': [2], 'strides': [1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64]}, 'name': 'conv1d_1', 'inbound_nodes': [[['dropout', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Add', 'config': {'name': 'add_1', 'trainable': True, 'dtype': 'float32'}, 'registered_name': None, 'build_config': {'input_shape': [[None, 64, 32], [None, 64, 32]]}, 'name': 'add_1', 'inbound_nodes': [[['conv1d_1', 0, 0, {}], ['add', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'LayerNormalization', 'config': {'name': 'layer_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': [2], 'epsilon': 1e-06, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'layer_normalization_2', 'inbound_nodes': [[['add_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'MultiHeadAttention', 'config': {'name': 'multi_head_attention_1', 'trainable': True, 'dtype': 'float32', 'num_heads': 2, 'key_dim': 32, 'value_dim': 32, 'dropout': 0.1, 'use_bias': True, 'output_shape': None, 'attention_axes': [1], 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None, 'query_shape': [None, 64, 32], 'key_shape': [None, 64, 32], 'value_shape': [None, 64, 32]}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'multi_head_attention_1', 'inbound_nodes': [[['layer_normalization_2', 0, 0, {'value': ['layer_normalization_2', 0, 0]}]]]}, {'module': 'keras.layers', 'class_name': 'Add', 'config': {'name': 'add_2', 'trainable': True, 'dtype': 'float32'}, 'registered_name': None, 'build_config': {'input_shape': [[None, 64, 32], [None, 64, 32]]}, 'name': 'add_2', 'inbound_nodes': [[['multi_head_attention_1', 0, 0, {}], ['add_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'LayerNormalization', 'config': {'name': 'layer_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': [2], 'epsilon': 1e-06, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'layer_normalization_3', 'inbound_nodes': [[['add_2', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d_2', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': [2], 'strides': [1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1], 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'conv1d_2', 'inbound_nodes': [[['layer_normalization_3', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64]}, 'name': 'dropout_1', 'inbound_nodes': [[['conv1d_2', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': [2], 'strides': [1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 64]}, 'name': 'conv1d_3', 'inbound_nodes': [[['dropout_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Add', 'config': {'name': 'add_3', 'trainable': True, 'dtype': 'float32'}, 'registered_name': None, 'build_config': {'input_shape': [[None, 64, 32], [None, 64, 32]]}, 'name': 'add_3', 'inbound_nodes': [[['conv1d_3', 0, 0, {}], ['add_2', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'GlobalAveragePooling1D', 'config': {'name': 'global_average_pooling1d', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last', 'keepdims': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 64, 32]}, 'name': 'global_average_pooling1d', 'inbound_nodes': [[['add_3', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 64, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 32]}, 'name': 'dense', 'inbound_nodes': [[['global_average_pooling1d', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64]}, 'name': 'dropout_2', 'inbound_nodes': [[['dense', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 32, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 64]}, 'name': 'dense_1', 'inbound_nodes': [[['dropout_2', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 32]}, 'name': 'dropout_3', 'inbound_nodes': [[['dense_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 32]}, 'name': 'dense_2', 'inbound_nodes': [[['dropout_3', 0, 0, {}]]]}], 'input_layers': [['input_1', 0, 0]], 'output_layers': [['dense_2', 0, 0]]}, 'keras_version': '2.13.1', 'backend': 'tensorflow'}}\n"
          ]
        }
      ],
      "source": [
        "# saving model architecture and hypermarameters\n",
        "model_info = {\n",
        "    \"model_name\": \"Vision Transformer\"\n",
        "}\n",
        "model_info[\"hyperparameters\"] = hyperparameters\n",
        "model_info[\"model_architecture\"] = model.to_json()\n",
        "model_info[\"model_architecture\"]  = json.loads(model_info[\"model_architecture\"] )\n",
        "\n",
        "path = os.path.join(os.path.dirname(os.getcwd()),'experiments','multi_headed_attention_mnist_dataset', 'mode_architecture.json')\n",
        "dump_json(model_info, path )\n",
        "print(model_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYkHMtFXGiuN"
      },
      "outputs": [],
      "source": [
        "transformed_test_images= get_transformed_test_images(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXuvne_5GiuO",
        "outputId": "0e001b6d-ca9a-44c0-fef5-64df74fdac4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 47s 34ms/step - loss: 0.1723 - accuracy: 0.9430\n",
            "1407/1407 [==============================] - 39s 28ms/step\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.1866 - accuracy: 0.9435\n",
            "469/469 [==============================] - 14s 31ms/step\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.1858 - accuracy: 0.9429\n",
            "313/313 [==============================] - 9s 29ms/step\n",
            "313/313 [==============================] - 9s 29ms/step - loss: 3.3355 - accuracy: 0.6694\n",
            "313/313 [==============================] - 9s 29ms/step\n",
            "{'model_name': 'Vision Transformer', 'train_images_performance_metrics': {'accuracy': 0.9430444240570068, 'precision': 0.9436927070787323, 'recall': 0.9420877265489679, 'f1_score': 0.9422721891708056}, 'validation_images_performance_metrics': {'accuracy': 0.9435333609580994, 'precision': 0.9438024712517473, 'recall': 0.9425949696819353, 'f1_score': 0.9427020690781334}, 'test_images_performance_metrics': {'accuracy': 0.9429000020027161, 'precision': 0.9440102443234146, 'recall': 0.9418122581187565, 'f1_score': 0.9421103523277411}, 'transformed_test_images_performance_metrics': {'accuracy': 0.6693999767303467, 'precision': 0.7721902514267633, 'recall': 0.6645088858253737, 'f1_score': 0.6914443995671273}}\n"
          ]
        }
      ],
      "source": [
        "#saving model performance metrics\n",
        "model_performance_metrics = {\n",
        "    \"model_name\": \"Vision Transformer\"\n",
        "}\n",
        "model_performance_metrics[\"train_images_performance_metrics\"] = get_model_performance_metrics(model,train_images, train_labels)\n",
        "model_performance_metrics[\"validation_images_performance_metrics\"] = get_model_performance_metrics(model,val_images, val_labels)\n",
        "model_performance_metrics[\"test_images_performance_metrics\"] = get_model_performance_metrics(model, test_images, test_labels)\n",
        "model_performance_metrics[\"transformed_test_images_performance_metrics\"] = get_model_performance_metrics(model, transformed_test_images, test_labels)\n",
        "\n",
        "\n",
        "path = os.path.join(os.path.dirname(os.getcwd()),'experiments','multi_headed_attention_mnist_dataset', 'mode_performance_metrics.json')\n",
        "dump_json(model_performance_metrics, path)\n",
        "print(model_performance_metrics)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}