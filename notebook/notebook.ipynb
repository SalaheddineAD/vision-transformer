{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CAREER\\MIU\\research assistant\\vision-transformer\\venv\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_transform(image):\n",
    "    choice = random.randint(0, 5)\n",
    "\n",
    "    rows, cols, _ = image.shape\n",
    "\n",
    "    if choice == 0: # Translation\n",
    "        tx, ty = random.randint(-20, 20), random.randint(-20, 20)\n",
    "        M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "        return cv2.warpAffine(image, M, (cols, rows))\n",
    "\n",
    "    elif choice == 1: # Rotation\n",
    "        angle = random.randint(-30, 30)\n",
    "        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "        return cv2.warpAffine(image, M, (cols, rows))\n",
    "\n",
    "    elif choice == 2: # Scaling\n",
    "        scale_factor = random.uniform(0.8, 1.2)\n",
    "        return cv2.resize(image, None, fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "    elif choice == 3: # Skewing\n",
    "        pts1 = np.float32([[5,5],[20,5],[5,20]])\n",
    "        pt1 = 5+10*np.random.uniform()-10/2\n",
    "        pt2 = 20+10*np.random.uniform()-10/2\n",
    "        pts2 = np.float32([[pt1,5],[pt2,pt1],[5,pt2]])\n",
    "        M = cv2.getAffineTransform(pts1,pts2)\n",
    "        return cv2.warpAffine(image, M, (cols, rows))\n",
    "\n",
    "    elif choice == 4: # Perspective distortion\n",
    "        pts1 = np.float32([[5,5],[20,5],[5,20],[20,20]])\n",
    "        pts2 = np.float32([[0,0],[20,5],[5,20],[20,20]])\n",
    "        M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "        return cv2.warpPerspective(image, M, (cols, rows))\n",
    "\n",
    "    else: # Pincushion distortion\n",
    "        distortion = np.float32([1, 1, 0, 0])\n",
    "        camera_matrix = np.eye(3)\n",
    "        return cv2.undistort(image, camera_matrix, distortion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Preprocess images\n",
    "new_shape = (32, 32)\n",
    "train_images = np.array([cv2.resize(img, new_shape) for img in train_images])\n",
    "test_images = np.array([cv2.resize(img, new_shape) for img in test_images])\n",
    "\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "train_images = train_images[..., tf.newaxis].astype(\"float32\")\n",
    "test_images = test_images[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "# Build the ViT model\n",
    "input_shape = (*new_shape, 1)\n",
    "patch_size = 4\n",
    "num_heads = 2\n",
    "num_patches = (new_shape[0] // patch_size) * (new_shape[1] // patch_size)\n",
    "projection_dim = 32\n",
    "num_transformer_layers = 2\n",
    "mlp_head_units = [64, 32]\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "x = tf.keras.layers.Conv2D(3, (3, 3), padding=\"same\")(inputs)  # Convert to 3 channels\n",
    "x = tf.keras.layers.Rescaling(1.0 / 255)(x)  # Rescale\n",
    "x = tf.keras.layers.Conv2D(32, (patch_size, patch_size), strides=patch_size)(x)\n",
    "x = tf.keras.layers.Reshape((num_patches, 32))(x)\n",
    "\n",
    "for _ in range(num_transformer_layers):\n",
    "    x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "    )(x1, x1)\n",
    "    x2 = tf.keras.layers.Add()([attention_output, x])\n",
    "    x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "    x3 = tf.keras.layers.Conv1D(64, 2, padding=\"same\", activation=\"relu\")(x3)\n",
    "    x3 = tf.keras.layers.Dropout(0.1)(x3)\n",
    "    x3 = tf.keras.layers.Conv1D(32, 2, padding=\"same\")(x3)\n",
    "    x = tf.keras.layers.Add()([x3, x2])\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "for dim in mlp_head_units:\n",
    "    x = tf.keras.layers.Dense(dim, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model\n",
    "model.fit(train_images, train_labels, epochs=1, batch_size=32)\n",
    "\n",
    "# Evaluate and report as before...\n",
    "\n",
    "# Applying transformations to test images\n",
    "# Applying transformations to test images\n",
    "# Applying transformations to test images\n",
    "# Applying transformations to test images\n",
    "transformed_test_images = []\n",
    "for img in test_images:\n",
    "    transformed_img = random_transform(img)\n",
    "    transformed_test_images.append(transformed_img)\n",
    "\n",
    "# Checking for shape consistency\n",
    "first_shape = transformed_test_images[0].shape\n",
    "for i, img in enumerate(transformed_test_images):\n",
    "    if img.shape != first_shape:\n",
    "        print(f\"Inconsistent shape at index {i}: expected {first_shape}, but got {img.shape}\")\n",
    "\n",
    "# Add more diagnostic code if needed\n",
    "\n",
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(transformed_test_images, test_labels)\n",
    "\n",
    "# Getting Precision, Recall, and F1 Score\n",
    "y_pred = model.predict(transformed_test_images)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(test_labels, y_pred_labels, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
